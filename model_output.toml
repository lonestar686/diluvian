random_seed = 1

[postprocessing]
#closing_shape = null  # To use: uncomment and replace null with value

[network]
initialization = "glorot_uniform"
batch_normalization = false
transpose = false
num_modules = 8
convolution_filters = 32
rescale_image = false
convolution_padding = "same"
convolution_activation = "relu"
dropout_probability = 0.05000000000000000
convolution_dim = [3, 3, 3]
unet_downsample_rate = [0, 1, 1]
output_activation = "sigmoid"
num_layers_per_module = 2
factory = "diluvian.network.make_flood_fill_unet"
unet_depth = 4

[model]
move_priority = "descending"
output_fov_move_fraction = 4
output_fov_shape = [13, 33, 33]
move_check_thickness = 1
v_true = 0.94999999999999996
t_final = 0.90000000000000002
move_recheck = true
input_fov_shape = [13, 33, 33]
v_false = 0.05000000000000000
training_subv_shape = [19, 49, 49]
t_move = 0.90000000000000002
validation_subv_shape = [25, 65, 65]

[volume]
resolution = [40, 16, 16]
label_downsampling = "majority"

[optimizer]
nesterov = true
lr = 0.00100000000000000
klass = "SGD"
momentum = 0.50000000000000000
loss = "binary_crossentropy"

[training]
num_gpus = 1
batch_size = 32
#fill_factor_bins = null  # To use: uncomment and replace null with value
#early_abort_epoch = null  # To use: uncomment and replace null with value
num_workers = 4
relabel_seed_component = false
validation_size = 128
reset_generators = false
augment_artifacts = []
augment_use_both = true
augment_validation = true
total_epochs = 2
#early_abort_loss = null  # To use: uncomment and replace null with value
gpu_batch_size = 32
label_erosion = [0, 1, 1]
training_size = 1024
patience = 20
augment_mirrors = [0, 1, 2]
augment_permute_axes = [[0, 2, 1]]

[training.validation_partition]
".*" = [1, 0, 0]

[training.training_partition]
".*" = [0, 0, 0]

[[training.augment_contrast]]
axis = 0
scaling_std = 0.10000000000000001
prob = 0.05000000000000000
center_std = 0.20000000000000001
center_mean = 1.19999999999999996
scaling_mean = 0.50000000000000000

[[training.augment_missing_data]]
axis = 0
prob = 0.01000000000000000

[training.validation_metric]
metric = "diluvian.util.binary_f_score"
mode = "max"
threshold = true

[training.validation_metric.args]
beta = 0.50000000000000000

[training.partitions]
".*" = [2, 1, 1]

[[training.augment_noise]]
axis = 0
mul = 0.05000000000000000
add = 0.05000000000000000
